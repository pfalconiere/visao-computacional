# üìÑ Document Classifier - RVL-CDIP

Sistema inteligente de classifica√ß√£o de documentos que diferencia **Advertisements** de **Scientific Articles**, com an√°lise avan√ßada de par√°grafos, extra√ß√£o de texto via OCR e verifica√ß√£o de conformidade com regras acad√™micas.

![Accuracy](https://img.shields.io/badge/Accuracy-90.00%25-brightgreen)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Casos de Uso](#casos-de-uso)
  - [Caso de Uso 1: Classifica√ß√£o de Tipo de Documento](#caso-de-uso-1-classifica√ß√£o-de-tipo-de-documento)
  - [Caso de Uso 2: Detec√ß√£o e Quantifica√ß√£o de Par√°grafos](#caso-de-uso-2-detec√ß√£o-e-quantifica√ß√£o-de-par√°grafos)
  - [Caso de Uso 3: Extra√ß√£o de Texto e Palavras Frequentes](#caso-de-uso-3-extra√ß√£o-de-texto-e-palavras-frequentes)
  - [Caso de Uso 4: Verifica√ß√£o de Conformidade](#caso-de-uso-4-verifica√ß√£o-de-conformidade)
- [Arquitetura](#arquitetura)
- [Instala√ß√£o](#instala√ß√£o)
- [Como Usar](#como-usar)
- [API REST](#api-rest)
- [Performance](#performance)
- [Tecnologias](#tecnologias)

---

## üéØ Vis√£o Geral

Este projeto implementa um classificador de documentos treinado no dataset **RVL-CDIP** com **90% de acur√°cia**, capaz de diferenciar an√∫ncios publicit√°rios de artigos cient√≠ficos. O sistema vai al√©m da simples classifica√ß√£o, oferecendo an√°lise estrutural e de conte√∫do dos documentos.

### Principais Features

‚úÖ Classifica√ß√£o bin√°ria de documentos (Advertisement vs Scientific Article)  
‚úÖ Detec√ß√£o autom√°tica de par√°grafos com algoritmo calibrado  
‚úÖ Extra√ß√£o de texto via OCR (Tesseract)  
‚úÖ An√°lise de palavras mais frequentes  
‚úÖ Verifica√ß√£o de conformidade com regras acad√™micas configur√°veis  
‚úÖ API REST completa com documenta√ß√£o Swagger  
‚úÖ Interface web moderna e responsiva  
‚úÖ Sistema de feedback para retreinamento  

---

## üìö Casos de Uso

### Caso de Uso 1: Classifica√ß√£o de Tipo de Documento

#### üìù Descri√ß√£o
Classifica automaticamente um documento TIFF como **Advertisement** (an√∫ncio publicit√°rio) ou **Scientific Article** (artigo cient√≠fico) com base em caracter√≠sticas visuais e estruturais.

#### üîç Como Funciona

O classificador analisa m√∫ltiplas features extra√≠das da imagem:

1. **Densidade de Texto**: Propor√ß√£o de pixels de texto em rela√ß√£o √† √°rea total
2. **N√∫mero de Componentes**: Quantidade de elementos de texto detectados
3. **Altura M√©dia dos Componentes**: Tamanho m√©dio das linhas de texto
4. **Desvio Padr√£o da Altura**: Varia√ß√£o no tamanho das linhas
5. **Aspect Ratio**: Propor√ß√£o entre largura e altura dos componentes

O modelo aplica **regras ponderadas otimizadas** atrav√©s de 50.000 itera√ß√µes de treinamento:

```python
# Pesos otimizados (classificador_final.py, linhas 52-58)
self.pesos = {
    'p1': 3.0802891803113677,  # Densidade de texto
    'p2': 1.6107505780934257,  # N√∫mero de componentes
    'p3': 0.7447718755081227,  # Altura m√©dia
    'p4': 0.6455914619059228,  # Desvio padr√£o
    'p5': 2.42                  # Transi√ß√µes de layout
}
```

#### üìÇ Arquivos Envolvidos

**`classificador_final.py`** (Arquivo principal)
- **Linhas 34-77**: Classe `ClassificadorFinal` e inicializa√ß√£o de thresholds
- **Linhas 78-158**: M√©todo `extract_features()` - Extra√ß√£o de caracter√≠sticas visuais
- **Linhas 160-236**: M√©todo `classify()` - L√≥gica de classifica√ß√£o com regras ponderadas
- **Linhas 42-49**: Thresholds otimizados calibrados com dataset RVL-CDIP

**`api.py`** (Endpoint de classifica√ß√£o)
- **Linhas 70-179**: Endpoint `/classify` - Processa upload e retorna classifica√ß√£o
- **Linhas 111-116**: Extra√ß√£o de features da imagem
- **Linhas 118-123**: Aplica√ß√£o do modelo de classifica√ß√£o

**`index.html`** (Interface Frontend)
- **Linhas 1107-1141**: Fun√ß√£o `classifyImage()` - Envia imagem para API
- **Linhas 1144-1223**: Fun√ß√£o `displayResult()` - Exibe resultado da classifica√ß√£o

#### üéØ Acur√°cia do Modelo

- **Acur√°cia Geral**: 90.00%
- **Advertisement**: 90.46%
- **Scientific Article**: 89.30%
- **Total de Amostras**: 5,085 documentos

#### üí° Exemplo de Uso

```python
from classificador_final import ClassificadorFinal

# Inicializar classificador
classifier = ClassificadorFinal()

# Classificar documento
result = classifier.classify("document.tif")

print(f"Tipo: {result['classification']}")
# Output: "Tipo: scientific_article" ou "Tipo: advertisement"
```

---

### Caso de Uso 2: Detec√ß√£o e Quantifica√ß√£o de Par√°grafos

#### üìù Descri√ß√£o
Detecta automaticamente par√°grafos em artigos cient√≠ficos atrav√©s de an√°lise de indenta√ß√£o, espa√ßamento vertical e estrutura de linhas.

#### üîç Como Funciona

O algoritmo implementa **3 estrat√©gias de detec√ß√£o calibradas**:

1. **Detec√ß√£o por Indenta√ß√£o**
   - Identifica recuos no in√≠cio de linhas (‚â•20px)
   - Diferencia primeira linha de continua√ß√µes de par√°grafo

2. **Detec√ß√£o por Espa√ßamento Vertical**
   - Analisa espa√ßos maiores entre linhas (‚â•3.0x a altura m√©dia)
   - Identifica quebras naturais de par√°grafo

3. **Detec√ß√£o por An√°lise de Fluxo**
   - Combina indenta√ß√£o + espa√ßamento
   - Identifica mudan√ßas no fluxo de texto

#### üìÇ Arquivos Envolvidos

**`paragraph_detector.py`** (Detector especializado)
- **Linhas 6-11**: Classe `ParagraphDetector` e par√¢metros calibrados
  ```python
  self.min_line_height = 5
  self.indent_threshold_px = 20      # Calibrado: 20px
  self.vertical_space_ratio = 3.0    # Calibrado: 3.0x
  ```
- **Linhas 12-59**: M√©todo `detect_text_lines_with_margins()` - Detec√ß√£o de linhas com margens
- **Linhas 61-91**: M√©todo `detect_by_indentation()` - Estrat√©gia de indenta√ß√£o
- **Linhas 93-113**: M√©todo `detect_by_vertical_space()` - Estrat√©gia de espa√ßamento
- **Linhas 115-123**: M√©todo `detect_paragraphs()` - M√©todo principal unificado

**`classificador_final.py`** (Integra√ß√£o)
- **Linhas 14-22**: Importa√ß√£o do `ParagraphDetector`
- **Linhas 60-64**: Inicializa√ß√£o do detector
- **Linhas 201-206**: Chamada da detec√ß√£o de par√°grafos
  ```python
  if self.paragraph_detector:
      num_paragraphs = self.paragraph_detector.detect_paragraphs(img)
  ```

**`api.py`** (Resposta da API)
- **Linhas 126-130**: Retorno do n√∫mero de par√°grafos detectados
  ```python
  'num_paragraphs': result.get('num_paragraphs', 0)
  ```

**`index.html`** (Exibi√ß√£o no Frontend)
- **Linhas 1174-1189**: Exibi√ß√£o de par√°grafos para artigos cient√≠ficos
  ```javascript
  if (!isAd && data.num_paragraphs !== undefined) {
      const paragraphDiv = document.createElement('div');
      paragraphDiv.innerHTML = `<strong>${t.paragraphs}:</strong> ${data.num_paragraphs}`;
  }
  ```

#### üéØ Par√¢metros Calibrados

O detector foi calibrado com dados reais do RVL-CDIP:

| Par√¢metro | Valor | Descri√ß√£o |
|-----------|-------|-----------|
| `min_line_height` | 5px | Altura m√≠nima de uma linha v√°lida |
| `indent_threshold_px` | 20px | Recuo m√≠nimo para considerar indenta√ß√£o |
| `vertical_space_ratio` | 3.0x | Espa√ßo vertical relativo √† altura m√©dia |

#### üí° Exemplo de Uso

```python
from paragraph_detector import ParagraphDetector
import cv2

detector = ParagraphDetector()
img = cv2.imread("scientific_article.tif", cv2.IMREAD_GRAYSCALE)

num_paragraphs = detector.detect_paragraphs(img)
print(f"Par√°grafos detectados: {num_paragraphs}")
# Output: "Par√°grafos detectados: 12"
```

---

### Caso de Uso 3: Extra√ß√£o de Texto e Palavras Frequentes

#### üìù Descri√ß√£o
Extrai o texto completo de artigos cient√≠ficos via OCR (Tesseract) e identifica as **10 palavras mais frequentes**, excluindo stopwords.

#### üîç Como Funciona

O processo de an√°lise de texto segue 4 etapas:

1. **OCR (Optical Character Recognition)**
   - Utiliza Tesseract OCR para extrair texto
   - Pr√©-processamento com threshold OTSU para melhor qualidade

2. **Limpeza e Normaliza√ß√£o**
   - Remove pontua√ß√£o e caracteres especiais
   - Converte para min√∫sculas

3. **Filtragem de Stopwords**
   - Remove palavras comuns sem valor sem√¢ntico (PT e EN)
   - Exemplos: "o", "a", "de", "the", "and", "or"

4. **Contagem e Ranking**
   - Conta frequ√™ncia de cada palavra
   - Retorna top 10 palavras mais relevantes

#### üìÇ Arquivos Envolvidos

**`text_analyzer.py`** (Analisador de texto)
- **Linhas 11-19**: Classe `TextAnalyzer` e lista de stopwords
  ```python
  self.stopwords = set([
      'o', 'a', 'os', 'as', 'um', 'uma', 'de', 'do', 'da',
      'the', 'a', 'an', 'and', 'or', 'but', 'if', 'of', 'at'
  ])
  ```
- **Linhas 32-50**: M√©todo `extract_text()` - Extra√ß√£o via OCR
  ```python
  def extract_text(self, image_path):
      img = cv2.imread(str(image_path))
      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
      _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
      text = pytesseract.image_to_string(thresh, lang='eng')
      return text
  ```
- **Linhas 52-83**: M√©todo `analyze_text()` - An√°lise e contagem de palavras
- **Linhas 85-120**: M√©todo `get_word_count_and_frequent_words()` - Pipeline completo

**`classificador_final.py`** (Integra√ß√£o)
- **Linhas 24-32**: Importa√ß√£o do `TextAnalyzer`
- **Linhas 66-70**: Inicializa√ß√£o do analisador
- **Linhas 208-221**: An√°lise de texto para artigos cient√≠ficos
  ```python
  if result['classification'] == 'scientific_article' and self.text_analyzer:
      word_count, frequent_words = self.text_analyzer.get_word_count_and_frequent_words(image_path)
      result['word_count'] = word_count
      result['frequent_words'] = frequent_words
  ```

**`api.py`** (Resposta da API)
- **Linhas 131-136**: Inclus√£o de dados de texto na resposta
  ```python
  'word_count': result.get('word_count', 0),
  'frequent_words': result.get('frequent_words', [])
  ```

**`index.html`** (Exibi√ß√£o no Frontend)
- **Linhas 1182-1188**: Exibi√ß√£o da contagem de palavras
- **Linhas 1193-1217**: Renderiza√ß√£o da lista de palavras frequentes
  ```javascript
  data.frequent_words.slice(0, 10).forEach(item => {
      const li = document.createElement('li');
      li.innerHTML = `${item.word}: <strong>${item.count}</strong>`;
      wordsList.appendChild(li);
  });
  ```

#### üéØ Stopwords Filtradas

O sistema filtra **42 stopwords** comuns em portugu√™s e ingl√™s:

**Portugu√™s**: o, a, os, as, um, uma, de, do, da, dos, das, em, no, na, nos, nas, por, para, com, sem, sob, e, ou, mas, se, que, qual, quando, onde, como

**Ingl√™s**: the, a, an, and, or, but, if, of, at, by, for, with, about, as, into, through, to, from, in, on

#### üí° Exemplo de Sa√≠da

```json
{
  "word_count": 3247,
  "frequent_words": [
    {"word": "algorithm", "count": 42},
    {"word": "data", "count": 38},
    {"word": "results", "count": 31},
    {"word": "analysis", "count": 28},
    {"word": "method", "count": 25},
    {"word": "performance", "count": 22},
    {"word": "system", "count": 20},
    {"word": "model", "count": 18},
    {"word": "evaluation", "count": 16},
    {"word": "research", "count": 15}
  ]
}
```

---

### Caso de Uso 4: Verifica√ß√£o de Conformidade

#### üìù Descri√ß√£o
Verifica se artigos cient√≠ficos est√£o **conformes** com regras acad√™micas configur√°veis, considerando n√∫mero m√≠nimo de palavras e par√°grafos.

#### üîç Como Funciona

O sistema avalia dois crit√©rios principais:

1. **Contagem de Palavras**
   - Padr√£o: ‚â• 2000 palavras
   - Configur√°vel pelo usu√°rio

2. **N√∫mero de Par√°grafos**
   - Padr√£o: ‚â• 8 par√°grafos
   - Configur√°vel pelo usu√°rio

**L√≥gica de Conformidade:**
```
CONFORME ‚ü∫ (palavra_count > min_words) AND (num_paragraphs ‚â• min_paragraphs)
```

Se qualquer crit√©rio falhar, o documento √© marcado como **N√ÉO CONFORME**.

#### üìÇ Arquivos Envolvidos

**`api.py`** (L√≥gica de conformidade)
- **Linhas 87-93**: Recep√ß√£o de par√¢metros configur√°veis
  ```python
  min_words = int(request.form.get('min_words', 2000))
  min_paragraphs = int(request.form.get('min_paragraphs', 8))
  ```
- **Linhas 138-157**: Verifica√ß√£o de conformidade para artigos cient√≠ficos
  ```python
  if result['classification'] == 'scientific_article':
      word_count = result.get('word_count', 0)
      num_paragraphs = result.get('num_paragraphs', 0)
      
      # Verificar conformidade
      is_compliant = word_count > min_words and num_paragraphs >= min_paragraphs
      
      # Gerar explica√ß√£o bil√≠ngue
      if is_compliant:
          explanation_pt = f"Documento CONFORME..."
          explanation_en = f"Document COMPLIANT..."
      else:
          explanation_pt = f"Documento N√ÉO CONFORME..."
          explanation_en = f"Document NOT COMPLIANT..."
  ```
- **Linhas 166-172**: Resposta com status de conformidade
  ```python
  'is_compliant': is_compliant,
  'compliance_rules': {
      'min_words': min_words,
      'min_paragraphs': min_paragraphs
  }
  ```

**`index.html`** (Interface de Configura√ß√£o)
- **Linhas 894-895**: Vari√°veis de regras (padr√£o)
  ```javascript
  let minWords = 2000;
  let minParagraphs = 8;
  ```
- **Linhas 1113-1118**: Envio de par√¢metros para API
  ```javascript
  formData.append('min_words', minWords);
  formData.append('min_paragraphs', minParagraphs);
  ```
- **Linhas 1331-1393**: Fun√ß√£o `translateExplanation()` - Gera resumo de conformidade
  ```javascript
  if (isCompliant) {
      explanation += ` Documento CONFORME √†s normas (>${minWords} palavras 
                       e ‚â•${minParagraphs} par√°grafos): ${wordCount} palavras, 
                       ${numParagraphs} par√°grafos.`;
  } else {
      explanation += ` Documento N√ÉO CONFORME √†s normas: `;
      // Lista problemas encontrados
  }
  ```
- **Linhas 1286-1303**: Modal de configura√ß√£o de regras
  ```javascript
  function confirmRule() {
      minWords = parseInt(document.getElementById('modal-min-words').value) || 2000;
      minParagraphs = parseInt(document.getElementById('modal-min-paragraphs').value) || 8;
  }
  ```

**Componentes do Modal (HTML)**
- **Linhas 1444-1464**: Modal HTML para alterar regras
  ```html
  <div class="modal" id="rule-modal">
      <input type="number" id="modal-min-words" value="2000">
      <input type="number" id="modal-min-paragraphs" value="8">
  </div>
  ```

#### üéØ Regras Padr√£o

| Crit√©rio | Valor Padr√£o | Configur√°vel |
|----------|--------------|--------------|
| M√≠nimo de Palavras | 2000 | ‚úÖ Sim |
| M√≠nimo de Par√°grafos | 8 | ‚úÖ Sim |

#### üí° Exemplos de Resposta

**Documento CONFORME:**
```json
{
  "classification": "scientific_article",
  "word_count": 3247,
  "num_paragraphs": 12,
  "is_compliant": true,
  "explanation_pt": "Documento CONFORME √†s normas (>2000 palavras e ‚â•8 par√°grafos): 3247 palavras, 12 par√°grafos.",
  "explanation_en": "Document COMPLIANT with standards (>2000 words and ‚â•8 paragraphs): 3247 words, 12 paragraphs."
}
```

**Documento N√ÉO CONFORME:**
```json
{
  "classification": "scientific_article",
  "word_count": 1450,
  "num_paragraphs": 6,
  "is_compliant": false,
  "explanation_pt": "Documento N√ÉO CONFORME √†s normas: apenas 1450 palavras (m√≠nimo: 2000), apenas 6 par√°grafos (m√≠nimo: 8).",
  "explanation_en": "Document NOT COMPLIANT with standards: only 1450 words (minimum: 2000), only 6 paragraphs (minimum: 8)."
}
```

#### üé® Interface de Configura√ß√£o

O usu√°rio pode **alterar as regras** atrav√©s do bot√£o "Alterar Regra" no header:

1. Clica no bot√£o "Alterar Regra"
2. Modal aparece com inputs num√©ricos
3. Define novos valores para palavras e par√°grafos
4. Confirma e as novas regras s√£o aplicadas na pr√≥xima classifica√ß√£o

---

## üèóÔ∏è Arquitetura

### Arquitetura S√≠ncrona (Modo Fallback)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FRONTEND (index.html)                    ‚îÇ
‚îÇ  - Interface Web Responsiva                                  ‚îÇ
‚îÇ  - Upload de arquivos TIFF                                   ‚îÇ
‚îÇ  - Configura√ß√£o de regras                                    ‚îÇ
‚îÇ  - Exibi√ß√£o de resultados                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP POST /classify
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     API REST (api.py)                        ‚îÇ
‚îÇ  - Endpoint /classify                                        ‚îÇ
‚îÇ  - Endpoint /feedback                                        ‚îÇ
‚îÇ  - Documenta√ß√£o Swagger                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CLASSIFICADOR (classificador_final.py)          ‚îÇ
‚îÇ  - Extra√ß√£o de features visuais                              ‚îÇ
‚îÇ  - Modelo de classifica√ß√£o (90% acc)                         ‚îÇ
‚îÇ  - Integra√ß√£o com detectores                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                       ‚îÇ
          ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PARAGRAPH DETECTOR ‚îÇ  ‚îÇ      TEXT ANALYZER           ‚îÇ
‚îÇ  (paragraph_        ‚îÇ  ‚îÇ  (text_analyzer_optimized.py)‚îÇ
‚îÇ   detector.py)      ‚îÇ  ‚îÇ  - OCR (Tesseract)           ‚îÇ
‚îÇ  - Detec√ß√£o linhas  ‚îÇ  ‚îÇ  - Contagem palavras         ‚îÇ
‚îÇ  - An√°lise indent   ‚îÇ  ‚îÇ  - Palavras frequentes       ‚îÇ
‚îÇ  - Espa√ßamento      ‚îÇ  ‚îÇ  - Filtragem stopwords       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ‚ö° Arquitetura Ass√≠ncrona (Modo de Produ√ß√£o)

O sistema implementa processamento ass√≠ncrono para lidar com documentos pesados (especialmente artigos cient√≠ficos com OCR) sem causar timeouts.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  FRONTEND (index.html)                         ‚îÇ
‚îÇ  - Upload de arquivo                                           ‚îÇ
‚îÇ  - Polling autom√°tico de progresso                             ‚îÇ
‚îÇ  - Barra de progresso em tempo real                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ 1. POST /classify/async (arquivo em base64)
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  WEB SERVICE (api.py)                           ‚îÇ
‚îÇ  Container 1: Flask + Gunicorn                                  ‚îÇ
‚îÇ  - Recebe arquivo como bytes                                    ‚îÇ
‚îÇ  - Converte para base64                                         ‚îÇ
‚îÇ  - Submete task ao Celery                                       ‚îÇ
‚îÇ  - Retorna task_id imediatamente (202 Accepted)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ 2. Envia via Redis
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     REDIS (Message Broker)                      ‚îÇ
‚îÇ  - Fila de tarefas (broker)                                     ‚îÇ
‚îÇ  - Armazenamento de resultados (backend)                        ‚îÇ
‚îÇ  - M√°ximo 30 conex√µes simult√¢neas (Free tier)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ 3. Worker consome task
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               CELERY WORKER (tasks.py)                          ‚îÇ
‚îÇ  Container 2: Celery Process                                    ‚îÇ
‚îÇ  - Recebe file_base64 + filename                                ‚îÇ
‚îÇ  - Decodifica base64 ‚Üí bytes                                    ‚îÇ
‚îÇ  - Salva temporariamente no /tmp do worker                      ‚îÇ
‚îÇ  - Atualiza progresso (10%, 30%, 90%)                           ‚îÇ
‚îÇ  - Chama classificador                                          ‚îÇ
‚îÇ  - Remove arquivo tempor√°rio                                    ‚îÇ
‚îÇ  - Retorna resultado via Redis                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CLASSIFICADOR (classificador_final.py)              ‚îÇ
‚îÇ  - Extra√ß√£o de features                                          ‚îÇ
‚îÇ  - Detec√ß√£o de par√°grafos                                        ‚îÇ
‚îÇ  - OCR otimizado (text_analyzer_optimized.py)                    ‚îÇ
‚îÇ  - An√°lise de conformidade                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### üîÑ Fluxo de Processamento Ass√≠ncrono

**Passo 1: Submiss√£o**
```javascript
// Frontend submete arquivo
POST /classify/async
‚Üí Retorna: { task_id: "abc-123", status: "PENDING" }
```

**Passo 2: Polling**
```javascript
// Frontend faz polling a cada 2 segundos
GET /task/abc-123
‚Üí Retorna: { 
    state: "PROGRESS", 
    progress: 30, 
    status: "Classificando documento..." 
}
```

**Passo 3: Conclus√£o**
```javascript
// Worker completa o processamento
GET /task/abc-123
‚Üí Retorna: { 
    state: "SUCCESS", 
    result: { classification: "scientific_article", ... } 
}
```

#### üì¶ Arquivos da Solu√ß√£o Ass√≠ncrona

**`celery_config.py`** - Configura√ß√£o do Celery
```python
# Cria inst√¢ncia do Celery conectada ao Redis
celery_app = Celery(
    'document_classifier',
    broker=REDIS_URL,      # Fila de tarefas
    backend=REDIS_URL      # Armazenamento de resultados
)
```

**`tasks.py`** - Defini√ß√£o de Tarefas
```python
@celery_app.task(bind=True, name='tasks.classify_document')
def classify_document(self, file_base64, filename, ...):
    # 1. Decodifica base64 ‚Üí bytes
    file_bytes = base64.b64decode(file_base64)
    
    # 2. Salva temporariamente
    with open(temp_path, 'wb') as f:
        f.write(file_bytes)
    
    # 3. Atualiza progresso
    self.update_state(state='PROGRESS', meta={...})
    
    # 4. Classifica
    result = classifier.classify(temp_path, ...)
    
    # 5. Remove arquivo
    os.remove(temp_path)
    
    return result
```

**`api.py`** - Endpoints Ass√≠ncronos
```python
# Endpoint para submeter tarefa
@app.route('/classify/async', methods=['POST'])
def classify_async():
    file_bytes = file.read()
    file_base64 = base64.b64encode(file_bytes).decode('utf-8')
    
    task = classify_document.apply_async(
        args=[file_base64, filename, ...]
    )
    
    return jsonify({'task_id': task.id})

# Endpoint para consultar status
@app.route('/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    task = classify_document.AsyncResult(task_id)
    
    if task.state == 'PROGRESS':
        return jsonify({
            'state': task.state,
            'progress': task.info.get('progress', 0),
            'status': task.info.get('status', '')
        })
    elif task.state == 'SUCCESS':
        return jsonify({
            'state': task.state,
            'result': task.info
        })
```

**`index.html`** - Frontend com Polling
```javascript
// 1. Submete arquivo
const response = await fetch('/classify/async', {
    method: 'POST',
    body: formData
});
const data = await response.json();

// 2. Inicia polling
pollTaskStatus(data.task_id);

// 3. Polling a cada 2 segundos
async function pollTaskStatus(taskId) {
    const response = await fetch(`/task/${taskId}`);
    const data = await response.json();
    
    if (data.state === 'PROGRESS') {
        updateProgress(data.progress, data.status);
        setTimeout(() => pollTaskStatus(taskId), 2000);
    } else if (data.state === 'SUCCESS') {
        displayResult(data.result);
    }
}
```

#### üê≥ Deploy com Docker Compose (Local)

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  web:
    build: .
    command: gunicorn -w 1 -b 0.0.0.0:5000 --timeout 180 api:app
    ports:
      - "5000:5000"
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis

  worker:
    build: .
    command: celery -A celery_config.celery_app worker --loglevel=info --concurrency=1
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
```

#### üöÄ Deploy em Produ√ß√£o (Render)

**Render Standard Plan** ($25/m√™s por servi√ßo):

1. **Redis** (Free tier): Message broker e result backend
2. **Web Service** (Standard): Flask API com 1 Gunicorn worker
3. **Background Worker** (Standard): Celery worker para processamento

**Procfile:**
```
web: gunicorn -w 1 -b 0.0.0.0:$PORT --timeout 180 api:app
worker: celery -A celery_config.celery_app worker --loglevel=info --concurrency=1
```

#### ‚ö†Ô∏è Desafio Arquitetural Resolvido

**Problema:** Containers separados n√£o compartilham filesystem
```
Web Container:  /tmp/arquivo.tif  ‚ùå
Worker Container: /tmp/  (vazio)
```

**Solu√ß√£o:** Transfer√™ncia via Redis
```
Web: arquivo ‚Üí bytes ‚Üí base64 ‚Üí Redis
Worker: Redis ‚Üí base64 ‚Üí bytes ‚Üí /tmp worker ‚Üí processa
```

#### üéØ Benef√≠cios da Arquitetura Ass√≠ncrona

‚úÖ **Sem timeouts**: Processamento em background independente do HTTP timeout  
‚úÖ **Escal√°vel**: M√∫ltiplos workers podem processar tarefas em paralelo  
‚úÖ **Feedback em tempo real**: Barra de progresso atualizada via polling  
‚úÖ **Resiliente**: Retry autom√°tico em caso de falha  
‚úÖ **Rastre√°vel**: Task ID permite consultar status a qualquer momento

---

## üì¶ Instala√ß√£o

### Pr√©-requisitos

- Python 3.8+
- Tesseract OCR

### Instalar Tesseract

**macOS:**
```bash
brew install tesseract
```

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr tesseract-ocr-eng
```

**Windows:**
Baixe o instalador em: https://github.com/UB-Mannheim/tesseract/wiki

### Instalar Depend√™ncias Python

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/document-classifier.git
cd document-classifier

# Instale as depend√™ncias
pip install -r requirements.txt
```

### Conte√∫do do `requirements.txt`

```txt
flask==3.0.0
flask-cors==4.0.0
flasgger==0.9.7.1
opencv-python==4.8.1.78
numpy==1.24.3
pytesseract==0.3.10
Pillow==10.1.0
```

---

## üöÄ Como Usar

### 1. Iniciar o Sistema (Linux/macOS)

```bash
bash start.sh
```

Este comando:
- Inicia a API na porta 5000
- Inicia o frontend na porta 8080
- Abre o navegador automaticamente

### 2. Iniciar Manualmente

**API:**
```bash
python3 api.py
```

**Frontend:**
```bash
python3 servidor_web.py
```

### 3. Acessar a Aplica√ß√£o

- **Frontend**: http://localhost:8080
- **API Docs**: http://localhost:5000/api/docs

### 4. Parar o Sistema

```bash
bash stop.sh
```

Ou manualmente:
```bash
pkill -f api.py
pkill -f servidor_web.py
```

---

## üîå API REST

### Endpoint: Classificar Documento

**POST** `/classify`

#### Request (multipart/form-data)

```bash
curl -X POST http://localhost:5000/classify \
  -F "image=@document.tif" \
  -F "min_words=2000" \
  -F "min_paragraphs=8" \
  -F "language=pt"
```

#### Response

```json
{
  "success": true,
  "classification": "scientific_article",
  "confidence": 0.95,
  "num_paragraphs": 12,
  "word_count": 3247,
  "frequent_words": [
    {"word": "algorithm", "count": 42},
    {"word": "data", "count": 38}
  ],
  "is_compliant": true,
  "explanation_pt": "Documento CONFORME √†s normas...",
  "explanation_en": "Document COMPLIANT with standards...",
  "features": {
    "text_density": 0.42,
    "num_text_components": 523,
    "avg_component_height": 15.3
  }
}
```

### Endpoint: Enviar Feedback

**POST** `/feedback`

```bash
curl -X POST http://localhost:5000/feedback \
  -H "Content-Type: application/json" \
  -d '{
    "image_name": "document.tif",
    "predicted_class": "scientific_article",
    "is_correct": "true",
    "correct_class": "scientific_article"
  }'
```

### Documenta√ß√£o Completa

Acesse a documenta√ß√£o interativa Swagger em: http://localhost:5000/api/docs

---

## üìä Performance

### M√©tricas do Modelo

| M√©trica | Valor |
|---------|-------|
| **Acur√°cia Geral** | 90.00% |
| **Precision (Advertisement)** | 90.46% |
| **Recall (Scientific Article)** | 89.30% |
| **Total de Amostras** | 5,085 |
| **Itera√ß√µes de Treinamento** | 50,000 |

### Detec√ß√£o de Par√°grafos

- **Acur√°cia M√©dia**: ~85%
- **Falsos Positivos**: <5%
- **Tempo de Processamento**: ~0.3s por imagem

### Extra√ß√£o de Texto (OCR)

- **Taxa de Sucesso**: ~92% (texto leg√≠vel)
- **Tempo M√©dio**: ~2-3s por p√°gina
- **Idiomas Suportados**: Ingl√™s (primary)

---

## üõ†Ô∏è Tecnologias

### Backend
- **Python 3.8+**
- **Flask** - Framework web
- **OpenCV** - Processamento de imagem
- **NumPy** - Computa√ß√£o num√©rica
- **Tesseract OCR** - Extra√ß√£o de texto
- **Flasgger** - Documenta√ß√£o Swagger

### Frontend
- **HTML5 / CSS3**
- **JavaScript (ES6+)**
- **Tiff.js** - Renderiza√ß√£o de TIFF no navegador

### Machine Learning
- **Feature Engineering** - 9 features extra√≠das
- **Weighted Rule-Based Classifier** - Otimizado com 50k itera√ß√µes
- **Calibrated Thresholds** - Ajustados no dataset RVL-CDIP

---

## üìÅ Estrutura do Projeto

```
document_classifier_project/
‚îú‚îÄ‚îÄ api.py                      # API REST principal
‚îú‚îÄ‚îÄ classificador_final.py      # Modelo de classifica√ß√£o
‚îú‚îÄ‚îÄ paragraph_detector.py       # Detector de par√°grafos
‚îú‚îÄ‚îÄ text_analyzer.py           # Analisador de texto (OCR)
‚îú‚îÄ‚îÄ swagger_docs.py            # Documenta√ß√£o Swagger
‚îú‚îÄ‚îÄ servidor_web.py            # Servidor frontend
‚îú‚îÄ‚îÄ index.html                 # Interface web
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias Python
‚îú‚îÄ‚îÄ start.sh                   # Script de inicializa√ß√£o
‚îú‚îÄ‚îÄ stop.sh                    # Script para parar servidores
‚îú‚îÄ‚îÄ training_data.pkl          # Dados de treinamento
‚îú‚îÄ‚îÄ feedback_data.csv          # Dados de feedback
‚îî‚îÄ‚îÄ docs/                      # Documenta√ß√£o adicional
    ‚îú‚îÄ‚îÄ API_README.md
    ‚îú‚îÄ‚îÄ COMO_TESTAR_API.md
    ‚îú‚îÄ‚îÄ GUIA_RAPIDO.md
    ‚îî‚îÄ‚îÄ TECHNICAL_DETAILS.md
```

---

## üß™ Testes

### Testar Classifica√ß√£o

```python
from classificador_final import ClassificadorFinal

classifier = ClassificadorFinal()

# Testar advertisement
result = classifier.classify("samples/advertisement.tif")
assert result['classification'] == 'advertisement'

# Testar scientific article
result = classifier.classify("samples/scientific_article.tif")
assert result['classification'] == 'scientific_article'
assert result['num_paragraphs'] > 0
assert result['word_count'] > 0
```

### Testar API

```bash
# Health check
curl http://localhost:5000/health

# Classificar documento
curl -X POST http://localhost:5000/classify \
  -F "image=@test_document.tif" \
  -F "min_words=2000" \
  -F "min_paragraphs=8"
```

---

## üìà Roadmap

- [x] Classifica√ß√£o bin√°ria (Advertisement vs Scientific Article)
- [x] Detec√ß√£o de par√°grafos
- [x] Extra√ß√£o de texto via OCR
- [x] An√°lise de palavras frequentes
- [x] Verifica√ß√£o de conformidade
- [x] API REST com Swagger
- [x] Interface web responsiva
- [x] Sistema de feedback
- [ ] Suporte a m√∫ltiplos idiomas no OCR
- [ ] Retreinamento autom√°tico com feedback
- [ ] Classifica√ß√£o multi-classe (10 categorias RVL-CDIP)
- [ ] Deploy em Cloud (AWS/Azure/GCP)
- [ ] Batch processing de m√∫ltiplos documentos
- [ ] Exporta√ß√£o de relat√≥rios em PDF

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## üìÑ Licen√ßa

Este projeto √© parte do trabalho do **Mestrado de Engenharia de Software 2025.1** do **C.E.S.A.R**.

MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## üë• Autores

**Projeto desenvolvido como parte do Mestrado de Engenharia de Software 2025.1**

üè¢ **C.E.S.A.R - Centro de Estudos e Sistemas Avan√ßados do Recife**

---

## üìû Suporte

Para quest√µes, bugs ou sugest√µes:

- üìß Email: [seu-email@example.com]
- üêõ Issues: [GitHub Issues](https://github.com/seu-usuario/document-classifier/issues)
- üìö Documenta√ß√£o: [Wiki](https://github.com/seu-usuario/document-classifier/wiki)

---

## üôè Agradecimentos

- **RVL-CDIP Dataset** - Dataset p√∫blico de classifica√ß√£o de documentos
- **Tesseract OCR** - Engine de OCR open-source
- **OpenCV Community** - Biblioteca de vis√£o computacional
- **Flask Team** - Framework web minimalista e poderoso

---

<div align="center">

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela no GitHub! ‚≠ê**

Made with ‚ù§Ô∏è by C.E.S.A.R Students

</div>
