# ğŸ“„ Document Classifier - RVL-CDIP

Sistema inteligente de classificaÃ§Ã£o de documentos que diferencia **Advertisements** de **Scientific Articles**, com anÃ¡lise avanÃ§ada de parÃ¡grafos, extraÃ§Ã£o de texto via OCR e verificaÃ§Ã£o de conformidade com regras acadÃªmicas.

![Accuracy](https://img.shields.io/badge/Accuracy-90.00%25-brightgreen)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Casos de Uso](#casos-de-uso)
  - [Caso de Uso 1: ClassificaÃ§Ã£o de Tipo de Documento](#caso-de-uso-1-classificaÃ§Ã£o-de-tipo-de-documento)
  - [Caso de Uso 2: DetecÃ§Ã£o e QuantificaÃ§Ã£o de ParÃ¡grafos](#caso-de-uso-2-detecÃ§Ã£o-e-quantificaÃ§Ã£o-de-parÃ¡grafos)
  - [Caso de Uso 3: ExtraÃ§Ã£o de Texto e Palavras Frequentes](#caso-de-uso-3-extraÃ§Ã£o-de-texto-e-palavras-frequentes)
  - [Caso de Uso 4: VerificaÃ§Ã£o de Conformidade](#caso-de-uso-4-verificaÃ§Ã£o-de-conformidade)
- [Arquitetura](#arquitetura)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Como Usar](#como-usar)
- [API REST](#api-rest)
- [Performance](#performance)
- [Tecnologias](#tecnologias)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um classificador de documentos treinado no dataset **RVL-CDIP** com **90% de acurÃ¡cia**, capaz de diferenciar anÃºncios publicitÃ¡rios de artigos cientÃ­ficos. O sistema vai alÃ©m da simples classificaÃ§Ã£o, oferecendo anÃ¡lise estrutural e de conteÃºdo dos documentos.

### Principais Features

âœ… ClassificaÃ§Ã£o binÃ¡ria de documentos (Advertisement vs Scientific Article)  
âœ… DetecÃ§Ã£o automÃ¡tica de parÃ¡grafos com algoritmo calibrado  
âœ… ExtraÃ§Ã£o de texto via OCR (Tesseract)  
âœ… AnÃ¡lise de palavras mais frequentes  
âœ… VerificaÃ§Ã£o de conformidade com regras acadÃªmicas configurÃ¡veis  
âœ… API REST completa com documentaÃ§Ã£o Swagger  
âœ… Interface web moderna e responsiva  
âœ… Sistema de feedback para retreinamento  

---

## ğŸ“š Casos de Uso

### Caso de Uso 1: ClassificaÃ§Ã£o de Tipo de Documento

#### ğŸ“ DescriÃ§Ã£o
Classifica automaticamente um documento TIFF como **Advertisement** (anÃºncio publicitÃ¡rio) ou **Scientific Article** (artigo cientÃ­fico) com base em caracterÃ­sticas visuais e estruturais.

#### ğŸ” Como Funciona

O classificador analisa mÃºltiplas features extraÃ­das da imagem:

1. **Densidade de Texto**: ProporÃ§Ã£o de pixels de texto em relaÃ§Ã£o Ã  Ã¡rea total
2. **NÃºmero de Componentes**: Quantidade de elementos de texto detectados
3. **Altura MÃ©dia dos Componentes**: Tamanho mÃ©dio das linhas de texto
4. **Desvio PadrÃ£o da Altura**: VariaÃ§Ã£o no tamanho das linhas
5. **Aspect Ratio**: ProporÃ§Ã£o entre largura e altura dos componentes

O modelo aplica **regras ponderadas otimizadas** atravÃ©s de 50.000 iteraÃ§Ãµes de treinamento:

```python
# Pesos otimizados (classificador_final.py, linhas 52-58)
self.pesos = {
    'p1': 3.0802891803113677,  # Densidade de texto
    'p2': 1.6107505780934257,  # NÃºmero de componentes
    'p3': 0.7447718755081227,  # Altura mÃ©dia
    'p4': 0.6455914619059228,  # Desvio padrÃ£o
    'p5': 2.42                  # TransiÃ§Ãµes de layout
}
```

#### ğŸ“‚ Arquivos Envolvidos

**`classificador_final.py`** (Arquivo principal)
- **Linhas 34-77**: Classe `ClassificadorFinal` e inicializaÃ§Ã£o de thresholds
- **Linhas 78-158**: MÃ©todo `extract_features()` - ExtraÃ§Ã£o de caracterÃ­sticas visuais
- **Linhas 160-236**: MÃ©todo `classify()` - LÃ³gica de classificaÃ§Ã£o com regras ponderadas
- **Linhas 42-49**: Thresholds otimizados calibrados com dataset RVL-CDIP

**`api.py`** (Endpoint de classificaÃ§Ã£o)
- **Linhas 70-179**: Endpoint `/classify` - Processa upload e retorna classificaÃ§Ã£o
- **Linhas 111-116**: ExtraÃ§Ã£o de features da imagem
- **Linhas 118-123**: AplicaÃ§Ã£o do modelo de classificaÃ§Ã£o

**`index.html`** (Interface Frontend)
- **Linhas 1107-1141**: FunÃ§Ã£o `classifyImage()` - Envia imagem para API
- **Linhas 1144-1223**: FunÃ§Ã£o `displayResult()` - Exibe resultado da classificaÃ§Ã£o

#### ğŸ¯ AcurÃ¡cia do Modelo

- **AcurÃ¡cia Geral**: 90.00%
- **Advertisement**: 90.46%
- **Scientific Article**: 89.30%
- **Total de Amostras**: 5,085 documentos

#### ğŸ’¡ Exemplo de Uso

```python
from classificador_final import ClassificadorFinal

# Inicializar classificador
classifier = ClassificadorFinal()

# Classificar documento
result = classifier.classify("document.tif")

print(f"Tipo: {result['classification']}")
# Output: "Tipo: scientific_article" ou "Tipo: advertisement"
```

---

### Caso de Uso 2: DetecÃ§Ã£o e QuantificaÃ§Ã£o de ParÃ¡grafos

#### ğŸ“ DescriÃ§Ã£o
Detecta automaticamente parÃ¡grafos em artigos cientÃ­ficos atravÃ©s de anÃ¡lise de indentaÃ§Ã£o, espaÃ§amento vertical e estrutura de linhas.

#### ğŸ” Como Funciona

O algoritmo implementa **3 estratÃ©gias de detecÃ§Ã£o calibradas**:

1. **DetecÃ§Ã£o por IndentaÃ§Ã£o**
   - Identifica recuos no inÃ­cio de linhas (â‰¥20px)
   - Diferencia primeira linha de continuaÃ§Ãµes de parÃ¡grafo

2. **DetecÃ§Ã£o por EspaÃ§amento Vertical**
   - Analisa espaÃ§os maiores entre linhas (â‰¥3.0x a altura mÃ©dia)
   - Identifica quebras naturais de parÃ¡grafo

3. **DetecÃ§Ã£o por AnÃ¡lise de Fluxo**
   - Combina indentaÃ§Ã£o + espaÃ§amento
   - Identifica mudanÃ§as no fluxo de texto

#### ğŸ“‚ Arquivos Envolvidos

**`paragraph_detector.py`** (Detector especializado)
- **Linhas 6-11**: Classe `ParagraphDetector` e parÃ¢metros calibrados
  ```python
  self.min_line_height = 5
  self.indent_threshold_px = 20      # Calibrado: 20px
  self.vertical_space_ratio = 3.0    # Calibrado: 3.0x
  ```
- **Linhas 12-59**: MÃ©todo `detect_text_lines_with_margins()` - DetecÃ§Ã£o de linhas com margens
- **Linhas 61-91**: MÃ©todo `detect_by_indentation()` - EstratÃ©gia de indentaÃ§Ã£o
- **Linhas 93-113**: MÃ©todo `detect_by_vertical_space()` - EstratÃ©gia de espaÃ§amento
- **Linhas 115-123**: MÃ©todo `detect_paragraphs()` - MÃ©todo principal unificado

**`classificador_final.py`** (IntegraÃ§Ã£o)
- **Linhas 14-22**: ImportaÃ§Ã£o do `ParagraphDetector`
- **Linhas 60-64**: InicializaÃ§Ã£o do detector
- **Linhas 201-206**: Chamada da detecÃ§Ã£o de parÃ¡grafos
  ```python
  if self.paragraph_detector:
      num_paragraphs = self.paragraph_detector.detect_paragraphs(img)
  ```

**`api.py`** (Resposta da API)
- **Linhas 126-130**: Retorno do nÃºmero de parÃ¡grafos detectados
  ```python
  'num_paragraphs': result.get('num_paragraphs', 0)
  ```

**`index.html`** (ExibiÃ§Ã£o no Frontend)
- **Linhas 1174-1189**: ExibiÃ§Ã£o de parÃ¡grafos para artigos cientÃ­ficos
  ```javascript
  if (!isAd && data.num_paragraphs !== undefined) {
      const paragraphDiv = document.createElement('div');
      paragraphDiv.innerHTML = `<strong>${t.paragraphs}:</strong> ${data.num_paragraphs}`;
  }
  ```

#### ğŸ¯ ParÃ¢metros Calibrados

O detector foi calibrado com dados reais do RVL-CDIP:

| ParÃ¢metro | Valor | DescriÃ§Ã£o |
|-----------|-------|-----------|
| `min_line_height` | 5px | Altura mÃ­nima de uma linha vÃ¡lida |
| `indent_threshold_px` | 20px | Recuo mÃ­nimo para considerar indentaÃ§Ã£o |
| `vertical_space_ratio` | 3.0x | EspaÃ§o vertical relativo Ã  altura mÃ©dia |

#### ğŸ’¡ Exemplo de Uso

```python
from paragraph_detector import ParagraphDetector
import cv2

detector = ParagraphDetector()
img = cv2.imread("scientific_article.tif", cv2.IMREAD_GRAYSCALE)

num_paragraphs = detector.detect_paragraphs(img)
print(f"ParÃ¡grafos detectados: {num_paragraphs}")
# Output: "ParÃ¡grafos detectados: 12"
```

---

### Caso de Uso 3: ExtraÃ§Ã£o de Texto e Palavras Frequentes

#### ğŸ“ DescriÃ§Ã£o
Extrai o texto completo de artigos cientÃ­ficos via OCR (Tesseract) e identifica as **10 palavras mais frequentes**, excluindo stopwords.

#### ğŸ” Como Funciona

O processo de anÃ¡lise de texto segue 4 etapas:

1. **OCR (Optical Character Recognition)**
   - Utiliza Tesseract OCR para extrair texto
   - PrÃ©-processamento com threshold OTSU para melhor qualidade

2. **Limpeza e NormalizaÃ§Ã£o**
   - Remove pontuaÃ§Ã£o e caracteres especiais
   - Converte para minÃºsculas

3. **Filtragem de Stopwords**
   - Remove palavras comuns sem valor semÃ¢ntico (PT e EN)
   - Exemplos: "o", "a", "de", "the", "and", "or"

4. **Contagem e Ranking**
   - Conta frequÃªncia de cada palavra
   - Retorna top 10 palavras mais relevantes

#### ğŸ“‚ Arquivos Envolvidos

**`text_analyzer.py`** (Analisador de texto)
- **Linhas 11-19**: Classe `TextAnalyzer` e lista de stopwords
  ```python
  self.stopwords = set([
      'o', 'a', 'os', 'as', 'um', 'uma', 'de', 'do', 'da',
      'the', 'a', 'an', 'and', 'or', 'but', 'if', 'of', 'at'
  ])
  ```
- **Linhas 32-50**: MÃ©todo `extract_text()` - ExtraÃ§Ã£o via OCR
  ```python
  def extract_text(self, image_path):
      img = cv2.imread(str(image_path))
      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
      _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
      text = pytesseract.image_to_string(thresh, lang='eng')
      return text
  ```
- **Linhas 52-83**: MÃ©todo `analyze_text()` - AnÃ¡lise e contagem de palavras
- **Linhas 85-120**: MÃ©todo `get_word_count_and_frequent_words()` - Pipeline completo

**`classificador_final.py`** (IntegraÃ§Ã£o)
- **Linhas 24-32**: ImportaÃ§Ã£o do `TextAnalyzer`
- **Linhas 66-70**: InicializaÃ§Ã£o do analisador
- **Linhas 208-221**: AnÃ¡lise de texto para artigos cientÃ­ficos
  ```python
  if result['classification'] == 'scientific_article' and self.text_analyzer:
      word_count, frequent_words = self.text_analyzer.get_word_count_and_frequent_words(image_path)
      result['word_count'] = word_count
      result['frequent_words'] = frequent_words
  ```

**`api.py`** (Resposta da API)
- **Linhas 131-136**: InclusÃ£o de dados de texto na resposta
  ```python
  'word_count': result.get('word_count', 0),
  'frequent_words': result.get('frequent_words', [])
  ```

**`index.html`** (ExibiÃ§Ã£o no Frontend)
- **Linhas 1182-1188**: ExibiÃ§Ã£o da contagem de palavras
- **Linhas 1193-1217**: RenderizaÃ§Ã£o da lista de palavras frequentes
  ```javascript
  data.frequent_words.slice(0, 10).forEach(item => {
      const li = document.createElement('li');
      li.innerHTML = `${item.word}: <strong>${item.count}</strong>`;
      wordsList.appendChild(li);
  });
  ```

#### ğŸ¯ Stopwords Filtradas

O sistema filtra **42 stopwords** comuns em portuguÃªs e inglÃªs:

**PortuguÃªs**: o, a, os, as, um, uma, de, do, da, dos, das, em, no, na, nos, nas, por, para, com, sem, sob, e, ou, mas, se, que, qual, quando, onde, como

**InglÃªs**: the, a, an, and, or, but, if, of, at, by, for, with, about, as, into, through, to, from, in, on

#### ğŸ’¡ Exemplo de SaÃ­da

```json
{
  "word_count": 3247,
  "frequent_words": [
    {"word": "algorithm", "count": 42},
    {"word": "data", "count": 38},
    {"word": "results", "count": 31},
    {"word": "analysis", "count": 28},
    {"word": "method", "count": 25},
    {"word": "performance", "count": 22},
    {"word": "system", "count": 20},
    {"word": "model", "count": 18},
    {"word": "evaluation", "count": 16},
    {"word": "research", "count": 15}
  ]
}
```

---

### Caso de Uso 4: VerificaÃ§Ã£o de Conformidade

#### ğŸ“ DescriÃ§Ã£o
Verifica se artigos cientÃ­ficos estÃ£o **conformes** com regras acadÃªmicas configurÃ¡veis, considerando nÃºmero mÃ­nimo de palavras e parÃ¡grafos.

#### ğŸ” Como Funciona

O sistema avalia dois critÃ©rios principais:

1. **Contagem de Palavras**
   - PadrÃ£o: â‰¥ 2000 palavras
   - ConfigurÃ¡vel pelo usuÃ¡rio

2. **NÃºmero de ParÃ¡grafos**
   - PadrÃ£o: â‰¥ 8 parÃ¡grafos
   - ConfigurÃ¡vel pelo usuÃ¡rio

**LÃ³gica de Conformidade:**
```
CONFORME âŸº (palavra_count > min_words) AND (num_paragraphs â‰¥ min_paragraphs)
```

Se qualquer critÃ©rio falhar, o documento Ã© marcado como **NÃƒO CONFORME**.

#### ğŸ“‚ Arquivos Envolvidos

**`api.py`** (LÃ³gica de conformidade)
- **Linhas 87-93**: RecepÃ§Ã£o de parÃ¢metros configurÃ¡veis
  ```python
  min_words = int(request.form.get('min_words', 2000))
  min_paragraphs = int(request.form.get('min_paragraphs', 8))
  ```
- **Linhas 138-157**: VerificaÃ§Ã£o de conformidade para artigos cientÃ­ficos
  ```python
  if result['classification'] == 'scientific_article':
      word_count = result.get('word_count', 0)
      num_paragraphs = result.get('num_paragraphs', 0)
      
      # Verificar conformidade
      is_compliant = word_count > min_words and num_paragraphs >= min_paragraphs
      
      # Gerar explicaÃ§Ã£o bilÃ­ngue
      if is_compliant:
          explanation_pt = f"Documento CONFORME..."
          explanation_en = f"Document COMPLIANT..."
      else:
          explanation_pt = f"Documento NÃƒO CONFORME..."
          explanation_en = f"Document NOT COMPLIANT..."
  ```
- **Linhas 166-172**: Resposta com status de conformidade
  ```python
  'is_compliant': is_compliant,
  'compliance_rules': {
      'min_words': min_words,
      'min_paragraphs': min_paragraphs
  }
  ```

**`index.html`** (Interface de ConfiguraÃ§Ã£o)
- **Linhas 894-895**: VariÃ¡veis de regras (padrÃ£o)
  ```javascript
  let minWords = 2000;
  let minParagraphs = 8;
  ```
- **Linhas 1113-1118**: Envio de parÃ¢metros para API
  ```javascript
  formData.append('min_words', minWords);
  formData.append('min_paragraphs', minParagraphs);
  ```
- **Linhas 1331-1393**: FunÃ§Ã£o `translateExplanation()` - Gera resumo de conformidade
  ```javascript
  if (isCompliant) {
      explanation += ` Documento CONFORME Ã s normas (>${minWords} palavras 
                       e â‰¥${minParagraphs} parÃ¡grafos): ${wordCount} palavras, 
                       ${numParagraphs} parÃ¡grafos.`;
  } else {
      explanation += ` Documento NÃƒO CONFORME Ã s normas: `;
      // Lista problemas encontrados
  }
  ```
- **Linhas 1286-1303**: Modal de configuraÃ§Ã£o de regras
  ```javascript
  function confirmRule() {
      minWords = parseInt(document.getElementById('modal-min-words').value) || 2000;
      minParagraphs = parseInt(document.getElementById('modal-min-paragraphs').value) || 8;
  }
  ```

**Componentes do Modal (HTML)**
- **Linhas 1444-1464**: Modal HTML para alterar regras
  ```html
  <div class="modal" id="rule-modal">
      <input type="number" id="modal-min-words" value="2000">
      <input type="number" id="modal-min-paragraphs" value="8">
  </div>
  ```

#### ğŸ¯ Regras PadrÃ£o

| CritÃ©rio | Valor PadrÃ£o | ConfigurÃ¡vel |
|----------|--------------|--------------|
| MÃ­nimo de Palavras | 2000 | âœ… Sim |
| MÃ­nimo de ParÃ¡grafos | 8 | âœ… Sim |

#### ğŸ’¡ Exemplos de Resposta

**Documento CONFORME:**
```json
{
  "classification": "scientific_article",
  "word_count": 3247,
  "num_paragraphs": 12,
  "is_compliant": true,
  "explanation_pt": "Documento CONFORME Ã s normas (>2000 palavras e â‰¥8 parÃ¡grafos): 3247 palavras, 12 parÃ¡grafos.",
  "explanation_en": "Document COMPLIANT with standards (>2000 words and â‰¥8 paragraphs): 3247 words, 12 paragraphs."
}
```

**Documento NÃƒO CONFORME:**
```json
{
  "classification": "scientific_article",
  "word_count": 1450,
  "num_paragraphs": 6,
  "is_compliant": false,
  "explanation_pt": "Documento NÃƒO CONFORME Ã s normas: apenas 1450 palavras (mÃ­nimo: 2000), apenas 6 parÃ¡grafos (mÃ­nimo: 8).",
  "explanation_en": "Document NOT COMPLIANT with standards: only 1450 words (minimum: 2000), only 6 paragraphs (minimum: 8)."
}
```

#### ğŸ¨ Interface de ConfiguraÃ§Ã£o

O usuÃ¡rio pode **alterar as regras** atravÃ©s do botÃ£o "Alterar Regra" no header:

1. Clica no botÃ£o "Alterar Regra"
2. Modal aparece com inputs numÃ©ricos
3. Define novos valores para palavras e parÃ¡grafos
4. Confirma e as novas regras sÃ£o aplicadas na prÃ³xima classificaÃ§Ã£o

---

## ğŸ—ï¸ Arquitetura

### Arquitetura SÃ­ncrona (Modo Fallback)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (index.html)                    â”‚
â”‚  - Interface Web Responsiva                                  â”‚
â”‚  - Upload de arquivos TIFF                                   â”‚
â”‚  - ConfiguraÃ§Ã£o de regras                                    â”‚
â”‚  - ExibiÃ§Ã£o de resultados                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP POST /classify
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API REST (api.py)                        â”‚
â”‚  - Endpoint /classify                                        â”‚
â”‚  - Endpoint /feedback                                        â”‚
â”‚  - DocumentaÃ§Ã£o Swagger                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CLASSIFICADOR (classificador_final.py)          â”‚
â”‚  - ExtraÃ§Ã£o de features visuais                              â”‚
â”‚  - Modelo de classificaÃ§Ã£o (90% acc)                         â”‚
â”‚  - IntegraÃ§Ã£o com detectores                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚
          â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARAGRAPH DETECTOR â”‚  â”‚      TEXT ANALYZER           â”‚
â”‚  (paragraph_        â”‚  â”‚  (text_analyzer_optimized.py)â”‚
â”‚   detector.py)      â”‚  â”‚  - OCR (Tesseract)           â”‚
â”‚  - DetecÃ§Ã£o linhas  â”‚  â”‚  - Contagem palavras         â”‚
â”‚  - AnÃ¡lise indent   â”‚  â”‚  - Palavras frequentes       â”‚
â”‚  - EspaÃ§amento      â”‚  â”‚  - Filtragem stopwords       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš¡ Arquitetura AssÃ­ncrona (Modo de ProduÃ§Ã£o)

O sistema implementa processamento assÃ­ncrono para lidar com documentos pesados (especialmente artigos cientÃ­ficos com OCR) sem causar timeouts.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FRONTEND (index.html)                         â”‚
â”‚  - Upload de arquivo                                           â”‚
â”‚  - Polling automÃ¡tico de progresso                             â”‚
â”‚  - Barra de progresso em tempo real                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 1. POST /classify/async (arquivo em base64)
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  WEB SERVICE (api.py)                           â”‚
â”‚  Container 1: Flask + Gunicorn                                  â”‚
â”‚  - Recebe arquivo como bytes                                    â”‚
â”‚  - Converte para base64                                         â”‚
â”‚  - Submete task ao Celery                                       â”‚
â”‚  - Retorna task_id imediatamente (202 Accepted)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ 2. Envia via Redis
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     REDIS (Message Broker)                      â”‚
â”‚  - Fila de tarefas (broker)                                     â”‚
â”‚  - Armazenamento de resultados (backend)                        â”‚
â”‚  - MÃ¡ximo 30 conexÃµes simultÃ¢neas (Free tier)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ 3. Worker consome task
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               CELERY WORKER (tasks.py)                          â”‚
â”‚  Container 2: Celery Process                                    â”‚
â”‚  - Recebe file_base64 + filename                                â”‚
â”‚  - Decodifica base64 â†’ bytes                                    â”‚
â”‚  - Salva temporariamente no /tmp do worker                      â”‚
â”‚  - Atualiza progresso (10%, 30%, 90%)                           â”‚
â”‚  - Chama classificador                                          â”‚
â”‚  - Remove arquivo temporÃ¡rio                                    â”‚
â”‚  - Retorna resultado via Redis                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CLASSIFICADOR (classificador_final.py)              â”‚
â”‚  - ExtraÃ§Ã£o de features                                          â”‚
â”‚  - DetecÃ§Ã£o de parÃ¡grafos                                        â”‚
â”‚  - OCR otimizado (text_analyzer_optimized.py)                    â”‚
â”‚  - AnÃ¡lise de conformidade                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ”„ Fluxo de Processamento AssÃ­ncrono

**Passo 1: SubmissÃ£o**
```javascript
// Frontend submete arquivo
POST /classify/async
â†’ Retorna: { task_id: "abc-123", status: "PENDING" }
```

**Passo 2: Polling**
```javascript
// Frontend faz polling a cada 2 segundos
GET /task/abc-123
â†’ Retorna: { 
    state: "PROGRESS", 
    progress: 30, 
    status: "Classificando documento..." 
}
```

**Passo 3: ConclusÃ£o**
```javascript
// Worker completa o processamento
GET /task/abc-123
â†’ Retorna: { 
    state: "SUCCESS", 
    result: { classification: "scientific_article", ... } 
}
```

#### ğŸ“¦ Arquivos da SoluÃ§Ã£o AssÃ­ncrona

**`celery_config.py`** - ConfiguraÃ§Ã£o do Celery
```python
# Cria instÃ¢ncia do Celery conectada ao Redis
celery_app = Celery(
    'document_classifier',
    broker=REDIS_URL,      # Fila de tarefas
    backend=REDIS_URL      # Armazenamento de resultados
)
```

**`tasks.py`** - DefiniÃ§Ã£o de Tarefas
```python
@celery_app.task(bind=True, name='tasks.classify_document')
def classify_document(self, file_base64, filename, ...):
    # 1. Decodifica base64 â†’ bytes
    file_bytes = base64.b64decode(file_base64)
    
    # 2. Salva temporariamente
    with open(temp_path, 'wb') as f:
        f.write(file_bytes)
    
    # 3. Atualiza progresso
    self.update_state(state='PROGRESS', meta={...})
    
    # 4. Classifica
    result = classifier.classify(temp_path, ...)
    
    # 5. Remove arquivo
    os.remove(temp_path)
    
    return result
```

**`api.py`** - Endpoints AssÃ­ncronos
```python
# Endpoint para submeter tarefa
@app.route('/classify/async', methods=['POST'])
def classify_async():
    file_bytes = file.read()
    file_base64 = base64.b64encode(file_bytes).decode('utf-8')
    
    task = classify_document.apply_async(
        args=[file_base64, filename, ...]
    )
    
    return jsonify({'task_id': task.id})

# Endpoint para consultar status
@app.route('/task/<task_id>', methods=['GET'])
def get_task_status(task_id):
    task = classify_document.AsyncResult(task_id)
    
    if task.state == 'PROGRESS':
        return jsonify({
            'state': task.state,
            'progress': task.info.get('progress', 0),
            'status': task.info.get('status', '')
        })
    elif task.state == 'SUCCESS':
        return jsonify({
            'state': task.state,
            'result': task.info
        })
```

**`index.html`** - Frontend com Polling
```javascript
// 1. Submete arquivo
const response = await fetch('/classify/async', {
    method: 'POST',
    body: formData
});
const data = await response.json();

// 2. Inicia polling
pollTaskStatus(data.task_id);

// 3. Polling a cada 2 segundos
async function pollTaskStatus(taskId) {
    const response = await fetch(`/task/${taskId}`);
    const data = await response.json();
    
    if (data.state === 'PROGRESS') {
        updateProgress(data.progress, data.status);
        setTimeout(() => pollTaskStatus(taskId), 2000);
    } else if (data.state === 'SUCCESS') {
        displayResult(data.result);
    }
}
```

#### ğŸ³ Deploy com Docker Compose (Local)

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  web:
    build: .
    command: gunicorn -w 1 -b 0.0.0.0:5000 --timeout 180 api:app
    ports:
      - "5000:5000"
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis

  worker:
    build: .
    command: celery -A celery_config.celery_app worker --loglevel=info --concurrency=1
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis
```

#### ğŸš€ Deploy em ProduÃ§Ã£o (Render)

**Render Standard Plan** ($25/mÃªs por serviÃ§o):

1. **Redis** (Free tier): Message broker e result backend
2. **Web Service** (Standard): Flask API com 1 Gunicorn worker
3. **Background Worker** (Standard): Celery worker para processamento

**Procfile:**
```
web: gunicorn -w 1 -b 0.0.0.0:$PORT --timeout 180 api:app
worker: celery -A celery_config.celery_app worker --loglevel=info --concurrency=1
```

#### âš ï¸ Desafio Arquitetural Resolvido

**Problema:** Containers separados nÃ£o compartilham filesystem
```
Web Container:  /tmp/arquivo.tif  âŒ
Worker Container: /tmp/  (vazio)
```

**SoluÃ§Ã£o:** TransferÃªncia via Redis
```
Web: arquivo â†’ bytes â†’ base64 â†’ Redis
Worker: Redis â†’ base64 â†’ bytes â†’ /tmp worker â†’ processa
```

#### ğŸ¯ BenefÃ­cios da Arquitetura AssÃ­ncrona

âœ… **Sem timeouts**: Processamento em background independente do HTTP timeout  
âœ… **EscalÃ¡vel**: MÃºltiplos workers podem processar tarefas em paralelo  
âœ… **Feedback em tempo real**: Barra de progresso atualizada via polling  
âœ… **Resiliente**: Retry automÃ¡tico em caso de falha  
âœ… **RastreÃ¡vel**: Task ID permite consultar status a qualquer momento

---

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- Tesseract OCR

### Instalar Tesseract

**macOS:**
```bash
brew install tesseract
```

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install tesseract-ocr tesseract-ocr-eng
```

**Windows:**
Baixe o instalador em: https://github.com/UB-Mannheim/tesseract/wiki

### Instalar DependÃªncias Python

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/document-classifier.git
cd document-classifier

# Instale as dependÃªncias
pip install -r requirements.txt
```

### ConteÃºdo do `requirements.txt`

```txt
flask==3.0.0
flask-cors==4.0.0
flasgger==0.9.7.1
opencv-python==4.8.1.78
numpy==1.24.3
pytesseract==0.3.10
Pillow==10.1.0
```

---

## ğŸš€ Como Usar

### 1. Iniciar o Sistema (Linux/macOS)

```bash
bash start.sh
```

Este comando:
- Inicia a API na porta 5000
- Inicia o frontend na porta 8080
- Abre o navegador automaticamente

### 2. Iniciar Manualmente

**API:**
```bash
python3 api.py
```

**Frontend:**
```bash
python3 servidor_web.py
```

### 3. Acessar a AplicaÃ§Ã£o

- **Frontend**: http://localhost:8080
- **API Docs**: http://localhost:5000/api/docs

### 4. Parar o Sistema

```bash
bash stop.sh
```

Ou manualmente:
```bash
pkill -f api.py
pkill -f servidor_web.py
```

---

## ğŸ”Œ API REST

### Endpoint: Classificar Documento

**POST** `/classify`

#### Request (multipart/form-data)

```bash
curl -X POST http://localhost:5000/classify \
  -F "image=@document.tif" \
  -F "min_words=2000" \
  -F "min_paragraphs=8" \
  -F "language=pt"
```

#### Response

```json
{
  "success": true,
  "classification": "scientific_article",
  "confidence": 0.95,
  "num_paragraphs": 12,
  "word_count": 3247,
  "frequent_words": [
    {"word": "algorithm", "count": 42},
    {"word": "data", "count": 38}
  ],
  "is_compliant": true,
  "explanation_pt": "Documento CONFORME Ã s normas...",
  "explanation_en": "Document COMPLIANT with standards...",
  "features": {
    "text_density": 0.42,
    "num_text_components": 523,
    "avg_component_height": 15.3
  }
}
```

### Endpoint: Enviar Feedback

**POST** `/feedback`

```bash
curl -X POST http://localhost:5000/feedback \
  -H "Content-Type: application/json" \
  -d '{
    "image_name": "document.tif",
    "predicted_class": "scientific_article",
    "is_correct": "true",
    "correct_class": "scientific_article"
  }'
```

### DocumentaÃ§Ã£o Completa

Acesse a documentaÃ§Ã£o interativa Swagger em: http://localhost:5000/api/docs

---

## ğŸ“Š Performance

### MÃ©tricas do Modelo

| MÃ©trica | Valor |
|---------|-------|
| **AcurÃ¡cia Geral** | 90.00% |
| **Precision (Advertisement)** | 90.46% |
| **Recall (Scientific Article)** | 89.30% |
| **Total de Amostras** | 5,085 |
| **IteraÃ§Ãµes de Treinamento** | 50,000 |

### DetecÃ§Ã£o de ParÃ¡grafos

- **AcurÃ¡cia MÃ©dia**: ~85%
- **Falsos Positivos**: <5%
- **Tempo de Processamento**: ~0.3s por imagem

### ExtraÃ§Ã£o de Texto (OCR)

- **Taxa de Sucesso**: ~92% (texto legÃ­vel)
- **Tempo MÃ©dio**: ~2-3s por pÃ¡gina
- **Idiomas Suportados**: InglÃªs (primary)

---

## ğŸ› ï¸ Tecnologias

### Backend
- **Python 3.8+**
- **Flask** - Framework web
- **OpenCV** - Processamento de imagem
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Tesseract OCR** - ExtraÃ§Ã£o de texto
- **Flasgger** - DocumentaÃ§Ã£o Swagger

### Frontend
- **HTML5 / CSS3**
- **JavaScript (ES6+)**
- **Tiff.js** - RenderizaÃ§Ã£o de TIFF no navegador

### Machine Learning
- **Feature Engineering** - 9 features extraÃ­das
- **Weighted Rule-Based Classifier** - Otimizado com 50k iteraÃ§Ãµes
- **Calibrated Thresholds** - Ajustados no dataset RVL-CDIP

---

## ğŸ“ Estrutura do Projeto

```
document_classifier_project/
â”œâ”€â”€ api.py                      # API REST principal
â”œâ”€â”€ classificador_final.py      # Modelo de classificaÃ§Ã£o
â”œâ”€â”€ paragraph_detector.py       # Detector de parÃ¡grafos
â”œâ”€â”€ text_analyzer.py           # Analisador de texto (OCR)
â”œâ”€â”€ swagger_docs.py            # DocumentaÃ§Ã£o Swagger
â”œâ”€â”€ servidor_web.py            # Servidor frontend
â”œâ”€â”€ index.html                 # Interface web
â”œâ”€â”€ requirements.txt           # DependÃªncias Python
â”œâ”€â”€ start.sh                   # Script de inicializaÃ§Ã£o
â”œâ”€â”€ stop.sh                    # Script para parar servidores
â”œâ”€â”€ training_data.pkl          # Dados de treinamento
â”œâ”€â”€ feedback_data.csv          # Dados de feedback
â””â”€â”€ docs/                      # DocumentaÃ§Ã£o adicional
    â”œâ”€â”€ API_README.md
    â”œâ”€â”€ COMO_TESTAR_API.md
    â”œâ”€â”€ GUIA_RAPIDO.md
    â””â”€â”€ TECHNICAL_DETAILS.md
```

---

## ğŸ§ª Testes

### Testar ClassificaÃ§Ã£o

```python
from classificador_final import ClassificadorFinal

classifier = ClassificadorFinal()

# Testar advertisement
result = classifier.classify("samples/advertisement.tif")
assert result['classification'] == 'advertisement'

# Testar scientific article
result = classifier.classify("samples/scientific_article.tif")
assert result['classification'] == 'scientific_article'
assert result['num_paragraphs'] > 0
assert result['word_count'] > 0
```

### Testar API

```bash
# Health check
curl http://localhost:5000/health

# Classificar documento
curl -X POST http://localhost:5000/classify \
  -F "image=@test_document.tif" \
  -F "min_words=2000" \
  -F "min_paragraphs=8"
```

---

## ğŸ“ˆ Roadmap

- [x] ClassificaÃ§Ã£o binÃ¡ria (Advertisement vs Scientific Article)
- [x] DetecÃ§Ã£o de parÃ¡grafos
- [x] ExtraÃ§Ã£o de texto via OCR
- [x] AnÃ¡lise de palavras frequentes
- [x] VerificaÃ§Ã£o de conformidade
- [x] API REST com Swagger
- [x] Interface web responsiva
- [x] Sistema de feedback
- [ ] Suporte a mÃºltiplos idiomas no OCR
- [ ] Retreinamento automÃ¡tico com feedback
- [ ] ClassificaÃ§Ã£o multi-classe (10 categorias RVL-CDIP)
- [ ] Deploy em Cloud (AWS/Azure/GCP)
- [ ] Batch processing de mÃºltiplos documentos
- [ ] ExportaÃ§Ã£o de relatÃ³rios em PDF

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte do trabalho do **Mestrado de Engenharia de Software 2025.1** do **C.E.S.A.R**.

MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ‘¥ Autores

**Projeto desenvolvido como parte do Mestrado de Engenharia de Software 2025.1**

ğŸ¢ **C.E.S.A.R - Centro de Estudos e Sistemas AvanÃ§ados do Recife**

---

## ğŸ“ Suporte

Para questÃµes, bugs ou sugestÃµes:

- ğŸ“§ Email: [seu-email@example.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/seu-usuario/document-classifier/issues)
- ğŸ“š DocumentaÃ§Ã£o: [Wiki](https://github.com/seu-usuario/document-classifier/wiki)

---

## ğŸ™ Agradecimentos

- **RVL-CDIP Dataset** - Dataset pÃºblico de classificaÃ§Ã£o de documentos
- **Tesseract OCR** - Engine de OCR open-source
- **OpenCV Community** - Biblioteca de visÃ£o computacional
- **Flask Team** - Framework web minimalista e poderoso

---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub! â­**

Made with â¤ï¸ by C.E.S.A.R Students

</div>
