{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classificador de Documentos: Advertisement vs Scientific Article\n",
        "\n",
        "Este notebook implementa regras de processamento de imagens para diferenciar documentos do tipo **advertisement** de **scientific_article** usando o dataset RVL-CDIP.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Instalação e Importação de Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalação de dependências necessárias\n",
        "!pip install opencv-python-headless numpy pillow matplotlib scikit-image scikit-learn scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Classe de Extração de Características\n",
        "\n",
        "### Características Distintivas:\n",
        "\n",
        "**Advertisement:**\n",
        "- Maior quantidade de cores\n",
        "- Imagens e gráficos coloridos\n",
        "- Layout não uniforme\n",
        "- Texto em tamanhos variados\n",
        "- Alta saturação de cores\n",
        "\n",
        "**Scientific Article:**\n",
        "- Predominantemente texto em preto/branco\n",
        "- Layout estruturado (colunas)\n",
        "- Baixa variação de cor\n",
        "- Texto uniforme\n",
        "- Possíveis gráficos/tabelas em preto e branco\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DocumentFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extrator de características visuais para classificação de documentos.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def load_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Carrega imagem em diferentes formatos.\n",
        "        \"\"\"\n",
        "        img = cv2.imread(str(image_path))\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Não foi possível carregar a imagem: {image_path}\")\n",
        "        return img\n",
        "    \n",
        "    def extract_color_features(self, img):\n",
        "        \"\"\"\n",
        "        Extrai características relacionadas a cores.\n",
        "        Advertisements tendem a ter mais cores e maior saturação.\n",
        "        \"\"\"\n",
        "        # Converter para HSV\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        \n",
        "        # Calcular saturação média\n",
        "        saturation_mean = np.mean(hsv[:, :, 1])\n",
        "        saturation_std = np.std(hsv[:, :, 1])\n",
        "        \n",
        "        # Calcular diversidade de cores usando histograma\n",
        "        hist_h = cv2.calcHist([hsv], [0], None, [180], [0, 180])\n",
        "        hist_s = cv2.calcHist([hsv], [1], None, [256], [0, 256])\n",
        "        \n",
        "        # Entropia do histograma (maior entropia = mais cores diferentes)\n",
        "        hist_h_norm = hist_h / (hist_h.sum() + 1e-7)\n",
        "        color_entropy = -np.sum(hist_h_norm * np.log2(hist_h_norm + 1e-7))\n",
        "        \n",
        "        # Contagem de cores únicas (simplificado)\n",
        "        img_resized = cv2.resize(img, (100, 100))\n",
        "        unique_colors = len(np.unique(img_resized.reshape(-1, 3), axis=0))\n",
        "        \n",
        "        return {\n",
        "            'saturation_mean': saturation_mean,\n",
        "            'saturation_std': saturation_std,\n",
        "            'color_entropy': color_entropy,\n",
        "            'unique_colors': unique_colors\n",
        "        }\n",
        "    \n",
        "    def extract_text_density(self, img):\n",
        "        \"\"\"\n",
        "        Analisa densidade de texto.\n",
        "        Scientific articles têm alta densidade de texto uniforme.\n",
        "        \"\"\"\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Binarização\n",
        "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "        \n",
        "        # Densidade de pixels pretos (texto)\n",
        "        text_density = np.sum(binary > 0) / binary.size\n",
        "        \n",
        "        # Análise de componentes conectados (palavras/blocos de texto)\n",
        "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
        "        \n",
        "        # Filtrar componentes pequenos (ruído)\n",
        "        min_area = 50\n",
        "        text_components = [stat for stat in stats[1:] if stat[cv2.CC_STAT_AREA] > min_area]\n",
        "        \n",
        "        return {\n",
        "            'text_density': text_density,\n",
        "            'num_text_components': len(text_components),\n",
        "            'avg_component_size': np.mean([s[cv2.CC_STAT_AREA] for s in text_components]) if text_components else 0\n",
        "        }\n",
        "    \n",
        "    def extract_layout_features(self, img):\n",
        "        \"\"\"\n",
        "        Analisa características de layout.\n",
        "        Scientific articles têm layout estruturado em colunas.\n",
        "        \"\"\"\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Projeção horizontal (soma de pixels por linha)\n",
        "        horizontal_projection = np.sum(gray < 128, axis=1)\n",
        "        \n",
        "        # Projeção vertical (soma de pixels por coluna)\n",
        "        vertical_projection = np.sum(gray < 128, axis=0)\n",
        "        \n",
        "        # Variância das projeções (artigos científicos têm padrões mais regulares)\n",
        "        h_proj_variance = np.var(horizontal_projection)\n",
        "        v_proj_variance = np.var(vertical_projection)\n",
        "        \n",
        "        # Detectar colunas através de vales na projeção vertical\n",
        "        v_proj_smoothed = cv2.GaussianBlur(vertical_projection.astype(float).reshape(-1, 1), (15, 1), 0).flatten()\n",
        "        v_proj_mean = np.mean(v_proj_smoothed)\n",
        "        \n",
        "        # Contar transições significativas (possíveis colunas)\n",
        "        threshold = v_proj_mean * 0.5\n",
        "        below_threshold = v_proj_smoothed < threshold\n",
        "        transitions = np.sum(np.diff(below_threshold.astype(int)) != 0)\n",
        "        \n",
        "        return {\n",
        "            'h_proj_variance': h_proj_variance,\n",
        "            'v_proj_variance': v_proj_variance,\n",
        "            'layout_transitions': transitions\n",
        "        }\n",
        "    \n",
        "    def extract_edge_features(self, img):\n",
        "        \"\"\"\n",
        "        Analisa características de bordas.\n",
        "        Advertisements têm mais bordas devido a imagens e gráficos.\n",
        "        \"\"\"\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Detectar bordas com Canny\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        \n",
        "        # Densidade de bordas\n",
        "        edge_density = np.sum(edges > 0) / edges.size\n",
        "        \n",
        "        # Detectar linhas com transformada de Hough\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n",
        "        num_lines = len(lines) if lines is not None else 0\n",
        "        \n",
        "        return {\n",
        "            'edge_density': edge_density,\n",
        "            'num_lines': num_lines\n",
        "        }\n",
        "    \n",
        "    def extract_all_features(self, image_path):\n",
        "        \"\"\"\n",
        "        Extrai todas as características de uma imagem.\n",
        "        \"\"\"\n",
        "        img = self.load_image(image_path)\n",
        "        \n",
        "        features = {}\n",
        "        features.update(self.extract_color_features(img))\n",
        "        features.update(self.extract_text_density(img))\n",
        "        features.update(self.extract_layout_features(img))\n",
        "        features.update(self.extract_edge_features(img))\n",
        "        \n",
        "        return features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Classificador Baseado em Regras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DocumentClassifier:\n",
        "    \"\"\"\n",
        "    Classificador baseado em regras para diferenciar Advertisement de Scientific Article.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.feature_extractor = DocumentFeatureExtractor()\n",
        "        \n",
        "        # Thresholds calibrados para o dataset RVL-CDIP\n",
        "        self.thresholds = {\n",
        "            'saturation_mean': 30,  # Ads têm saturação > 30\n",
        "            'color_entropy': 5.0,   # Ads têm entropia > 5.0\n",
        "            'text_density': 0.15,   # Scientific articles têm densidade > 0.15\n",
        "            'unique_colors': 2000,  # Ads têm mais cores únicas\n",
        "        }\n",
        "    \n",
        "    def calculate_score(self, features):\n",
        "        \"\"\"\n",
        "        Calcula score para classificação.\n",
        "        Score positivo = Advertisement\n",
        "        Score negativo = Scientific Article\n",
        "        \"\"\"\n",
        "        score = 0\n",
        "        \n",
        "        # Regra 1: Alta saturação sugere Advertisement\n",
        "        if features['saturation_mean'] > self.thresholds['saturation_mean']:\n",
        "            score += 2\n",
        "        else:\n",
        "            score -= 1\n",
        "        \n",
        "        # Regra 2: Alta entropia de cores sugere Advertisement\n",
        "        if features['color_entropy'] > self.thresholds['color_entropy']:\n",
        "            score += 2\n",
        "        else:\n",
        "            score -= 1\n",
        "        \n",
        "        # Regra 3: Alta densidade de texto sugere Scientific Article\n",
        "        if features['text_density'] > self.thresholds['text_density']:\n",
        "            score -= 2\n",
        "        else:\n",
        "            score += 1\n",
        "        \n",
        "        # Regra 4: Muitas cores únicas sugere Advertisement\n",
        "        if features['unique_colors'] > self.thresholds['unique_colors']:\n",
        "            score += 1\n",
        "        else:\n",
        "            score -= 1\n",
        "        \n",
        "        # Regra 5: Layout estruturado (baixa variância vertical) sugere Scientific Article\n",
        "        if features['v_proj_variance'] < 1e9:\n",
        "            score -= 1\n",
        "        \n",
        "        # Regra 6: Muitas transições de layout sugerem colunas (Scientific Article)\n",
        "        if features['layout_transitions'] > 10:\n",
        "            score -= 1\n",
        "        \n",
        "        return score\n",
        "    \n",
        "    def classify(self, image_path):\n",
        "        \"\"\"\n",
        "        Classifica uma imagem como Advertisement ou Scientific Article.\n",
        "        \"\"\"\n",
        "        features = self.feature_extractor.extract_all_features(image_path)\n",
        "        score = self.calculate_score(features)\n",
        "        \n",
        "        classification = 'advertisement' if score > 0 else 'scientific_article'\n",
        "        confidence = abs(score) / 10.0  # Normalizar para 0-1\n",
        "        \n",
        "        return {\n",
        "            'classification': classification,\n",
        "            'score': score,\n",
        "            'confidence': min(confidence, 1.0),\n",
        "            'features': features\n",
        "        }\n",
        "    \n",
        "    def visualize_classification(self, image_path, result):\n",
        "        \"\"\"\n",
        "        Visualiza o resultado da classificação.\n",
        "        \"\"\"\n",
        "        img = cv2.imread(str(image_path))\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Imagem original\n",
        "        axes[0].imshow(img_rgb)\n",
        "        axes[0].set_title(f\"Documento Original\", fontsize=14)\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Resultados\n",
        "        axes[1].axis('off')\n",
        "        result_text = f\"\"\"\n",
        "        CLASSIFICAÇÃO: {result['classification'].upper()}\n",
        "        \n",
        "        Score: {result['score']}\n",
        "        Confiança: {result['confidence']:.2%}\n",
        "        \n",
        "        CARACTERÍSTICAS EXTRAÍDAS:\n",
        "        \n",
        "        Cores:\n",
        "        - Saturação média: {result['features']['saturation_mean']:.2f}\n",
        "        - Entropia de cores: {result['features']['color_entropy']:.2f}\n",
        "        - Cores únicas: {result['features']['unique_colors']}\n",
        "        \n",
        "        Texto:\n",
        "        - Densidade: {result['features']['text_density']:.4f}\n",
        "        - Componentes: {result['features']['num_text_components']}\n",
        "        \n",
        "        Layout:\n",
        "        - Transições: {result['features']['layout_transitions']}\n",
        "        - Var. Vertical: {result['features']['v_proj_variance']:.2e}\n",
        "        \n",
        "        Bordas:\n",
        "        - Densidade: {result['features']['edge_density']:.4f}\n",
        "        - Linhas detectadas: {result['features']['num_lines']}\n",
        "        \"\"\"\n",
        "        \n",
        "        axes[1].text(0.1, 0.5, result_text, fontsize=11, family='monospace',\n",
        "                    verticalalignment='center')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Exemplo de Uso\n",
        "\n",
        "### 4.1 Configuração do Dataset\n",
        "\n",
        "Para usar o dataset RVL-CDIP:\n",
        "1. Baixe o dataset do Kaggle: https://www.kaggle.com/datasets/pdavpoojan/the-rvlcdip-dataset-test\n",
        "2. Extraia os arquivos\n",
        "3. Configure o caminho abaixo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure o caminho do dataset aqui\n",
        "DATASET_PATH = Path('/path/to/rvl-cdip-test')  # Ajuste conforme necessário\n",
        "\n",
        "# O dataset RVL-CDIP tem a seguinte estrutura:\n",
        "# - advertisement/\n",
        "# - scientific_article/  (ou scientific_publication/)\n",
        "# etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Classificar uma Imagem Individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar classificador\n",
        "classifier = DocumentClassifier()\n",
        "\n",
        "# Exemplo: classificar uma imagem\n",
        "# image_path = DATASET_PATH / 'advertisement' / 'image_001.png'\n",
        "# result = classifier.classify(image_path)\n",
        "# classifier.visualize_classification(image_path, result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Testar com Imagem de Exemplo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_classifier_on_sample(image_path):\n",
        "    \"\"\"\n",
        "    Testa o classificador em uma imagem e mostra os resultados.\n",
        "    \"\"\"\n",
        "    classifier = DocumentClassifier()\n",
        "    result = classifier.classify(image_path)\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(f\"Imagem: {Path(image_path).name}\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Classificação: {result['classification'].upper()}\")\n",
        "    print(f\"Score: {result['score']}\")\n",
        "    print(f\"Confiança: {result['confidence']:.2%}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    classifier.visualize_classification(image_path, result)\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Exemplo de uso:\n",
        "# test_classifier_on_sample('path/to/your/image.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Avaliação em Múltiplas Imagens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_classifier(ad_folder, article_folder, num_samples=10):\n",
        "    \"\"\"\n",
        "    Avalia o classificador em um conjunto de imagens.\n",
        "    \"\"\"\n",
        "    classifier = DocumentClassifier()\n",
        "    \n",
        "    results = {\n",
        "        'advertisement': {'correct': 0, 'total': 0},\n",
        "        'scientific_article': {'correct': 0, 'total': 0}\n",
        "    }\n",
        "    \n",
        "    # Testar advertisements\n",
        "    ad_images = list(Path(ad_folder).glob('*.png'))[:num_samples]\n",
        "    for img_path in ad_images:\n",
        "        try:\n",
        "            result = classifier.classify(img_path)\n",
        "            results['advertisement']['total'] += 1\n",
        "            if result['classification'] == 'advertisement':\n",
        "                results['advertisement']['correct'] += 1\n",
        "            print(f\"✓ {img_path.name}: {result['classification']} (score: {result['score']})\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Erro em {img_path.name}: {e}\")\n",
        "    \n",
        "    # Testar scientific articles\n",
        "    article_images = list(Path(article_folder).glob('*.png'))[:num_samples]\n",
        "    for img_path in article_images:\n",
        "        try:\n",
        "            result = classifier.classify(img_path)\n",
        "            results['scientific_article']['total'] += 1\n",
        "            if result['classification'] == 'scientific_article':\n",
        "                results['scientific_article']['correct'] += 1\n",
        "            print(f\"✓ {img_path.name}: {result['classification']} (score: {result['score']})\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Erro em {img_path.name}: {e}\")\n",
        "    \n",
        "    # Calcular métricas\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESULTADOS DA AVALIAÇÃO\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for doc_type, metrics in results.items():\n",
        "        if metrics['total'] > 0:\n",
        "            accuracy = metrics['correct'] / metrics['total']\n",
        "            print(f\"\\n{doc_type.upper()}:\")\n",
        "            print(f\"  Corretas: {metrics['correct']}/{metrics['total']}\")\n",
        "            print(f\"  Acurácia: {accuracy:.2%}\")\n",
        "    \n",
        "    total_correct = sum(m['correct'] for m in results.values())\n",
        "    total = sum(m['total'] for m in results.values())\n",
        "    overall_accuracy = total_correct / total if total > 0 else 0\n",
        "    \n",
        "    print(f\"\\nACURÁCIA GERAL: {overall_accuracy:.2%}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Exemplo de uso:\n",
        "# evaluate_classifier(\n",
        "#     ad_folder='path/to/advertisement',\n",
        "#     article_folder='path/to/scientific_article',\n",
        "#     num_samples=20\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Ajuste Fino dos Thresholds (Opcional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_feature_distribution(ad_folder, article_folder, num_samples=20):\n",
        "    \"\"\"\n",
        "    Analisa a distribuição de características para ajustar thresholds.\n",
        "    \"\"\"\n",
        "    extractor = DocumentFeatureExtractor()\n",
        "    \n",
        "    ad_features = []\n",
        "    article_features = []\n",
        "    \n",
        "    # Coletar features de advertisements\n",
        "    for img_path in list(Path(ad_folder).glob('*.png'))[:num_samples]:\n",
        "        try:\n",
        "            features = extractor.extract_all_features(img_path)\n",
        "            ad_features.append(features)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    # Coletar features de scientific articles\n",
        "    for img_path in list(Path(article_folder).glob('*.png'))[:num_samples]:\n",
        "        try:\n",
        "            features = extractor.extract_all_features(img_path)\n",
        "            article_features.append(features)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    # Visualizar distribuições\n",
        "    feature_names = ['saturation_mean', 'color_entropy', 'text_density', 'unique_colors']\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feature_name in enumerate(feature_names):\n",
        "        ad_values = [f[feature_name] for f in ad_features]\n",
        "        article_values = [f[feature_name] for f in article_features]\n",
        "        \n",
        "        axes[idx].hist(ad_values, alpha=0.5, label='Advertisement', bins=20, color='red')\n",
        "        axes[idx].hist(article_values, alpha=0.5, label='Scientific Article', bins=20, color='blue')\n",
        "        axes[idx].set_xlabel(feature_name)\n",
        "        axes[idx].set_ylabel('Frequência')\n",
        "        axes[idx].legend()\n",
        "        axes[idx].set_title(f'Distribuição: {feature_name}')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Estatísticas\n",
        "    print(\"\\nESTATÍSTICAS DAS CARACTERÍSTICAS:\")\n",
        "    print(\"=\"*80)\n",
        "    for feature_name in feature_names:\n",
        "        ad_values = [f[feature_name] for f in ad_features]\n",
        "        article_values = [f[feature_name] for f in article_features]\n",
        "        \n",
        "        print(f\"\\n{feature_name}:\")\n",
        "        print(f\"  Advertisement    - Média: {np.mean(ad_values):.2f}, Std: {np.std(ad_values):.2f}\")\n",
        "        print(f\"  Scientific Article - Média: {np.mean(article_values):.2f}, Std: {np.std(article_values):.2f}\")\n",
        "\n",
        "# Exemplo de uso:\n",
        "# analyze_feature_distribution(\n",
        "#     ad_folder='path/to/advertisement',\n",
        "#     article_folder='path/to/scientific_article',\n",
        "#     num_samples=30\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Resumo das Regras de Classificação\n",
        "\n",
        "### Regras Implementadas:\n",
        "\n",
        "1. **Saturação de Cores**: Advertisements têm cores mais saturadas (média > 30)\n",
        "2. **Entropia de Cores**: Advertisements têm maior diversidade de cores (entropia > 5.0)\n",
        "3. **Densidade de Texto**: Scientific articles têm maior densidade de texto (> 0.15)\n",
        "4. **Cores Únicas**: Advertisements têm mais cores únicas (> 2000 em imagem 100x100)\n",
        "5. **Layout Estruturado**: Scientific articles têm layout mais uniforme\n",
        "6. **Transições de Layout**: Scientific articles frequentemente têm colunas (> 10 transições)\n",
        "\n",
        "### Como Melhorar:\n",
        "\n",
        "- Coletar estatísticas do seu dataset específico usando `analyze_feature_distribution()`\n",
        "- Ajustar os thresholds em `DocumentClassifier.thresholds`\n",
        "- Adicionar mais regras baseadas em características específicas observadas\n",
        "- Considerar usar Machine Learning para classificação automática\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
